{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Smart Care - Baby Cry Analysis System\n",
                "\n",
                "This system uses AI to analyze infant crying sounds to identify needs such as hunger, pain, discomfort, or sleep."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import librosa\n",
                "import os\n",
                "import sounddevice as sd\n",
                "from tkinter import filedialog, messagebox, ttk\n",
                "import tkinter as tk\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D, MaxPooling1D, Flatten\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from collections import Counter\n",
                "from datetime import datetime\n",
                "from scipy.io.wavfile import write\n",
                "import noisereduce as nr\n",
                "import threading\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import confusion_matrix, classification_report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Main directory for audio data\n",
                "# ================================\n",
                "data_dir = \"donateacry_corpus\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Helper Functions\n",
                "# ================================\n",
                "def normalize_audio(audio):\n",
                "    \"\"\"Normalize audio signal to have consistent peak levels.\"\"\"\n",
                "    peak = np.abs(audio).max()\n",
                "    if peak > 0:\n",
                "        audio = audio / peak\n",
                "    return audio\n",
                "\n",
                "def clean_audio(audio, sample_rate=16000):\n",
                "    reduced_noise = nr.reduce_noise(y=audio, sr=sample_rate)\n",
                "    normalized_audio = normalize_audio(reduced_noise)\n",
                "    return librosa.util.normalize(normalized_audio)\n",
                "\n",
                "def extract_features(file_path):\n",
                "    try:\n",
                "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
                "        if len(audio) < 22050:  # Less than one second\n",
                "            raise ValueError(\"Audio file is too short.\")\n",
                "\n",
                "        audio = clean_audio(audio, sample_rate)\n",
                "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
                "        mfccs = librosa.util.fix_length(mfccs, size=100, axis=1)\n",
                "        delta = librosa.feature.delta(mfccs)\n",
                "        delta_delta = librosa.feature.delta(mfccs, order=2)\n",
                "        combined_features = np.vstack((mfccs, delta, delta_delta))\n",
                "        return np.mean(combined_features, axis=1)\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing file {file_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "def extract_features_from_audio_data(audio_data, sample_rate=16000):\n",
                "    \"\"\"Extract MFCC features from real-time audio data.\"\"\"\n",
                "    try:\n",
                "        if len(audio_data) < 22050:  # Less than one second\n",
                "            audio_data = np.pad(audio_data, (0, 22050 - len(audio_data)), 'constant')\n",
                "\n",
                "        audio = clean_audio(audio_data, sample_rate)\n",
                "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
                "        mfccs = librosa.util.fix_length(mfccs, size=100, axis=1)\n",
                "        delta = librosa.feature.delta(mfccs)\n",
                "        delta_delta = librosa.feature.delta(mfccs, order=2)\n",
                "        combined_features = np.vstack((mfccs, delta, delta_delta))\n",
                "        return np.mean(combined_features, axis=1)\n",
                "    except Exception as e:\n",
                "        print(f\"Error extracting features from audio data: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "data_processing",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Load and process data\n",
                "# ================================\n",
                "features = []\n",
                "labels = []\n",
                "\n",
                "for root, dirs, files in os.walk(data_dir):\n",
                "    for file in files:\n",
                "        if file.endswith((\".wav\", \".mp3\")):\n",
                "            file_path = os.path.join(root, file)\n",
                "            label = os.path.basename(root)\n",
                "            feature = extract_features(file_path)\n",
                "            if feature is not None:\n",
                "                features.append(feature)\n",
                "                labels.append(label)\n",
                "\n",
                "X = np.array(features)\n",
                "y = np.array(labels)\n",
                "\n",
                "label_encoder = LabelEncoder()\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "print(\"Before SMOTE:\", Counter(y_encoded))\n",
                "\n",
                "smote = SMOTE(random_state=42)\n",
                "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_encoded)\n",
                "\n",
                "print(\"After SMOTE:\", Counter(y_resampled))\n",
                "\n",
                "y_resampled_categorical = to_categorical(y_resampled)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_categorical, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "training",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Build and train the model\n",
                "# ================================\n",
                "input_layer = Input(shape=(X_train.shape[1], 1))\n",
                "x = Conv1D(32, 3, activation='relu')(input_layer)\n",
                "x = MaxPooling1D(2)(x)\n",
                "x = Conv1D(32, 3, activation='relu')(x)\n",
                "x = MaxPooling1D(2)(x)\n",
                "x = Conv1D(32, 3, activation='relu')(x)\n",
                "x = MaxPooling1D(2)(x)\n",
                "x = Flatten()(x)\n",
                "x = Dense(64, activation='relu')(x)\n",
                "x = Dropout(0.4)(x)\n",
                "output_layer = Dense(y_train.shape[1], activation='softmax')(x)\n",
                "\n",
                "model = Model(inputs=input_layer, outputs=output_layer)\n",
                "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
                "\n",
                "# Save the model\n",
                "model.save(\"baby_cry_model_cnn.keras\")\n",
                "print(\"Model saved as 'baby_cry_model_cnn.keras'.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plots",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Show training and validation accuracy/loss plots\n",
                "# ================================\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linestyle='--')\n",
                "plt.title('Training and Validation Accuracy')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--')\n",
                "plt.title('Training and Validation Loss')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cm",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Show Confusion Matrix\n",
                "# ================================\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "y_true_classes = np.argmax(y_test, axis=1)\n",
                "\n",
                "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
                "class_labels = label_encoder.classes_\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
                "plt.xlabel(\"Predicted Labels\")\n",
                "plt.ylabel(\"True Labels\")\n",
                "plt.title(\"Confusion Matrix\")\n",
                "plt.show()\n",
                "\n",
                "print(\"Classification Report:\")\n",
                "print(classification_report(y_true_classes, y_pred_classes, target_names=class_labels))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "smote_effect",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Show SMOTE Effect\n",
                "# ================================\n",
                "original_class_counts = Counter(y_encoded)\n",
                "resampled_class_counts = Counter(y_resampled)\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "bar_width = 0.35\n",
                "index = np.arange(len(original_class_counts))\n",
                "\n",
                "plt.bar(index, [original_class_counts[cls] for cls in original_class_counts], bar_width, label='Original', color='blue')\n",
                "plt.bar(index + bar_width, [resampled_class_counts[cls] for cls in resampled_class_counts], bar_width, label='After SMOTE', color='green')\n",
                "\n",
                "plt.xlabel('Classes')\n",
                "plt.ylabel('Number of Samples')\n",
                "plt.title('Class Distribution Before and After SMOTE')\n",
                "plt.legend()\n",
                "plt.xticks(index + bar_width / 2, [f'Class {cls}' for cls in original_class_counts])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gui_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Real-Time Prediction Logic & GUI Functions\n",
                "# ================================\n",
                "stop_real_time = False\n",
                "last_predictions = []\n",
                "\n",
                "def update_predictions_list():\n",
                "    last_predictions_listbox.delete(0, tk.END)\n",
                "    for prediction in last_predictions[-5:]:\n",
                "        entry = f\"{prediction['Name']} ({prediction['Age']}, {prediction['Gender']}): {prediction['Prediction']} at {prediction['Time']}\"\n",
                "        last_predictions_listbox.insert(tk.END, entry)\n",
                "\n",
                "def predict_audio_file():\n",
                "    child_name = name_entry.get().strip()\n",
                "    child_age = age_combobox.get().strip()\n",
                "    child_gender = gender_combobox.get().strip()\n",
                "\n",
                "    if not child_name or not child_age or not child_gender:\n",
                "        messagebox.showerror(\"Missing Information\", \"Please fill out all fields (Name, Age, and Gender).\")\n",
                "        return\n",
                "\n",
                "    file_path = filedialog.askopenfilename(filetypes=[(\"Audio Files\", \"*.wav;*.mp3\")])\n",
                "    if file_path:\n",
                "        feature = extract_features(file_path)\n",
                "        if feature is not None:\n",
                "            try:\n",
                "                feature_scaled = scaler.transform([feature])[..., np.newaxis]\n",
                "                predicted_probs = model.predict(feature_scaled)\n",
                "                predicted_label = np.argmax(predicted_probs)\n",
                "                predicted_label_name = label_encoder.inverse_transform([predicted_label])[0]\n",
                "\n",
                "                prediction_info = {\n",
                "                    \"Name\": child_name,\n",
                "                    \"Age\": child_age,\n",
                "                    \"Gender\": child_gender,\n",
                "                    \"Prediction\": predicted_label_name,\n",
                "                    \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
                "                }\n",
                "                last_predictions.append(prediction_info)\n",
                "                update_predictions_list()\n",
                "                messagebox.showinfo(\"Prediction Result\", f\"Prediction: {predicted_label_name}\")\n",
                "            except Exception as e:\n",
                "                messagebox.showerror(\"Error\", f\"An error occurred during prediction: {e}\")\n",
                "\n",
                "def record_audio_with_progress(duration, sample_rate):\n",
                "    progress_bar[\"value\"] = 0\n",
                "    progress_bar[\"maximum\"] = duration * 10\n",
                "    audio_data = []\n",
                "\n",
                "    for _ in range(int(duration * 10)):\n",
                "        if stop_real_time: \n",
                "            break\n",
                "        frame = sd.rec(int(sample_rate / 10), samplerate=sample_rate, channels=1, dtype=\"float32\")\n",
                "        sd.wait()\n",
                "        audio_data.extend(frame.flatten())\n",
                "        progress_bar[\"value\"] += 1\n",
                "        root.update_idletasks()\n",
                "\n",
                "    return np.array(audio_data)\n",
                "\n",
                "def is_significant_sound(audio_data, threshold=0.02):\n",
                "    energy = np.sum(np.square(audio_data)) / len(audio_data)\n",
                "    return energy > threshold\n",
                "\n",
                "def real_time_prediction():\n",
                "    global stop_real_time\n",
                "    duration = 10 \n",
                "    sample_rate = 16000\n",
                "    stop_real_time = False \n",
                "\n",
                "    def record_and_predict():\n",
                "        while not stop_real_time:\n",
                "            audio_data = record_audio_with_progress(duration, sample_rate)\n",
                "            if not is_significant_sound(audio_data):\n",
                "                messagebox.showwarning(\"No Sound\", \"No significant sound detected. Please try again.\")\n",
                "                continue\n",
                "\n",
                "            if len(audio_data) < sample_rate * 4:\n",
                "                messagebox.showwarning(\"Insufficient Data\", \"Audio data is insufficient for prediction. Please try again.\")\n",
                "                continue\n",
                "\n",
                "            try:\n",
                "                clean_data = clean_audio(audio_data)\n",
                "                feature = extract_features_from_audio_data(clean_data, sample_rate)\n",
                "                if feature is not None:\n",
                "                    feature_scaled = scaler.transform([feature])[..., np.newaxis]\n",
                "                    feature_reshaped = feature_scaled.reshape((feature_scaled.shape[0], feature_scaled.shape[1], 1))\n",
                "\n",
                "                    predicted_probs = model.predict(feature_reshaped)\n",
                "                    predicted_label = np.argmax(predicted_probs)\n",
                "                    confidence = np.max(predicted_probs) \n",
                "                    predicted_label_name = label_encoder.inverse_transform([predicted_label])[0]\n",
                "\n",
                "                    if confidence < 0.5: \n",
                "                        messagebox.showwarning(\"Low Confidence\", \"Prediction confidence is too low. Please try again.\")\n",
                "                        continue\n",
                "\n",
                "                    prediction_info = {\n",
                "                        \"Name\": \"Real-Time\",\n",
                "                        \"Age\": \"N/A\",\n",
                "                        \"Gender\": \"N/A\",\n",
                "                        \"Prediction\": predicted_label_name,\n",
                "                        \"Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
                "                    }\n",
                "                    last_predictions.append(prediction_info)\n",
                "                    update_predictions_list()\n",
                "                else:\n",
                "                    messagebox.showwarning(\"Feature Extraction Error\", \"Unable to extract valid features. Please try again.\")\n",
                "            except Exception as e:\n",
                "                messagebox.showerror(\"Prediction Error\", f\"An error occurred during prediction: {e}\")\n",
                "\n",
                "    prediction_thread = threading.Thread(target=record_and_predict)\n",
                "    prediction_thread.start()\n",
                "\n",
                "def stop_real_time_prediction():\n",
                "    global stop_real_time\n",
                "    if progress_bar[\"value\"] < 40:\n",
                "        messagebox.showwarning(\"Warning\", \"No audio detected. Recording stopped before sufficient data was captured.\")\n",
                "    stop_real_time = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gui_main",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ================================\n",
                "# Tkinter GUI Main Loop\n",
                "# ================================\n",
                "root = tk.Tk()\n",
                "root.title(\"Baby Cry Analysis System\")\n",
                "root.geometry(\"500x600\")\n",
                "root.config(bg=\"lightblue\")\n",
                "\n",
                "input_frame = tk.Frame(root, bg=\"lightblue\")\n",
                "input_frame.pack(pady=20)\n",
                "\n",
                "name_label = tk.Label(input_frame, text=\"Child's Name:\", bg=\"lightblue\", font=(\"Arial\", 12))\n",
                "name_label.grid(row=0, column=0, padx=5, pady=5)\n",
                "name_entry = ttk.Entry(input_frame) \n",
                "name_entry.grid(row=0, column=1, padx=5, pady=5)\n",
                "\n",
                "age_label = tk.Label(input_frame, text=\"Child's Age:\", bg=\"lightblue\", font=(\"Arial\", 12))\n",
                "age_label.grid(row=1, column=0, padx=10, pady=5)\n",
                "age_combobox = ttk.Combobox(input_frame, values=[\"0-3 months\", \"3-6 months\", \"6-12 months\", \"1-2 years\"])\n",
                "age_combobox.grid(row=1, column=1, padx=5, pady=5)\n",
                "\n",
                "gender_label = tk.Label(input_frame, text=\"Child's Gender:\", bg=\"lightblue\", font=(\"Arial\", 12))\n",
                "gender_label.grid(row=2, column=0, padx=5, pady=5)\n",
                "gender_combobox = ttk.Combobox(input_frame, values=[\"Male\", \"Female\"])\n",
                "gender_combobox.grid(row=2, column=1, padx=5, pady=5)\n",
                "\n",
                "button_frame = tk.Frame(root, bg=\"lightblue\")\n",
                "button_frame.pack(pady=20)\n",
                "\n",
                "predict_button = tk.Button(button_frame, text=\"Predict Audio File\", command=predict_audio_file, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
                "predict_button.grid(row=0, column=0, padx=10, pady=10)\n",
                "\n",
                "record_button = tk.Button(button_frame, text=\"Start Real-Time Prediction\", command=real_time_prediction, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
                "record_button.grid(row=0, column=1, padx=10, pady=10)\n",
                "\n",
                "stop_button = tk.Button(button_frame, text=\"Stop Real-Time Prediction\", command=stop_real_time_prediction, bg=\"#f44336\", fg=\"white\", font=(\"Arial\", 12))\n",
                "stop_button.grid(row=1, column=0, columnspan=2, pady=10)\n",
                "\n",
                "last_predictions_label = tk.Label(root, text=\"Last 5 Predictions:\", bg=\"lightblue\", font=(\"Arial\", 12))\n",
                "last_predictions_label.pack(pady=10)\n",
                "\n",
                "last_predictions_listbox = tk.Listbox(root, height=5, width=60)\n",
                "last_predictions_listbox.pack(pady=5)\n",
                "\n",
                "progress_bar = ttk.Progressbar(root, length=300, mode=\"determinate\")\n",
                "progress_bar.pack(pady=10)\n",
                "\n",
                "root.mainloop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}